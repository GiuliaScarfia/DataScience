{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac0bd619-c961-4f71-a1a6-e0def5fee2a6",
   "metadata": {},
   "source": [
    "## Esercizio 12.03.25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f0bb14-77cf-499d-8fde-7dab4f225546",
   "metadata": {},
   "source": [
    "*Introduzione*\n",
    "\n",
    "Lo scenario presenta un test medico utilizzato per prevedere la probabilità di anomalie cromosomiche in donne in gravidanza over 35. Il test ha un'alta sensibilità (90%) ma una bassa precisione, portando a un alto numero di falsi positivi e un F1-score di 0,15. La sfida è creare un dataset sintetico che rispecchi questo contesto, adattare un modello di classificazione e confrontare i suoi risultati con il test descritto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df2dc7b-c345-42d7-8cea-afedf3179d20",
   "metadata": {},
   "source": [
    "*Comprendere il Problema*\n",
    "\n",
    "*Punti chiave:*\n",
    "\n",
    "Prevalenza: 50 su 10.000 persone hanno la malattia.\n",
    "\n",
    "Sensibilità (Recall): 90% - Il test identifica correttamente il 90% delle persone che svilupperanno la malattia.\n",
    "\n",
    "Tasso di Falsi Positivi: 5% - Su 9.950 persone sane, 497 vengono erroneamente identificate come positive.\n",
    "\n",
    "Precisione: 8% - Solo l'8% dei risultati positivi del test sono veri positivi.\n",
    "\n",
    "F1-score: 0,15 - Una metrica che bilancia precisione e sensibilità.\n",
    "\n",
    "*Obiettivo:*\n",
    "\n",
    "-Creare un dataset sintetico con caratteristiche simili.\n",
    "\n",
    "-Adattare un modello di classificazione.\n",
    "\n",
    "-Confrontare le prestazioni del modello con il test descritto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "103dc311-cbae-465b-9dc2-44a7c0fc376b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risultati del modello:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2985\n",
      "           1       0.86      0.40      0.55        15\n",
      "\n",
      "    accuracy                           1.00      3000\n",
      "   macro avg       0.93      0.70      0.77      3000\n",
      "weighted avg       1.00      1.00      1.00      3000\n",
      "\n",
      "Matrice di confusione:\n",
      "[[2984    1]\n",
      " [   9    6]]\n",
      "F1-Score del Nuovo Modello: 0.5454545454545454\n",
      "F1-Score Originale: 0.15\n",
      "Il nuovo modello ha un F1-Score migliore rispetto al test originale.\n"
     ]
    }
   ],
   "source": [
    "# Importazione delle librerie necessarie\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "\n",
    "# 1. Creazione del set di dati sintetico\n",
    "# Parametri\n",
    "n_samples = 10000  # Numero totale di campioni\n",
    "prevalence = 0.005  # Prevalenza della malattia (0.5%)\n",
    "sensitivity = 0.90  # Sensibilità (recall) del test\n",
    "false_positive_rate = 0.05  # Tasso di falsi positivi del test\n",
    "\n",
    "# Creazione di un set di dati sintetico\n",
    "X, y = make_classification(\n",
    "    n_samples=n_samples,\n",
    "    n_features=10,  # Numero di caratteristiche (parametri misurati)\n",
    "    n_informative=5,  # Numero di caratteristiche informative\n",
    "    n_redundant=2,  # Numero di caratteristiche ridondanti\n",
    "    n_clusters_per_class=1,  # Numero di cluster per classe\n",
    "    weights=[1 - prevalence],  # Peso per la classe negativa (sani)\n",
    "    flip_y=0,  # Rumore nei dati (0 per nessun rumore)\n",
    "    random_state=42  # Seed per riproducibilità\n",
    ")\n",
    "\n",
    "# Conversione in un DataFrame per una migliore gestione\n",
    "df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(X.shape[1])])\n",
    "df['target'] = y\n",
    "\n",
    "# 2. Divisione del set di dati in training e test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop('target', axis=1),  # Features\n",
    "    df['target'],  # Target\n",
    "    test_size=0.3,  # 30% dei dati per il test set\n",
    "    random_state=42  # Seed per riproducibilità\n",
    ")\n",
    "\n",
    "# 3. Applicazione di SMOTE per bilanciare il set di dati\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 4. Addestramento del modello di classificazione (Random Forest)\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# 5. Predizione sul test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 6. Valutazione del modello\n",
    "print(\"Risultati del modello:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Matrice di confusione:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Calcolo dell'F1-Score\n",
    "new_f1_score = f1_score(y_test, y_pred)\n",
    "print(f\"F1-Score del Nuovo Modello: {new_f1_score}\")\n",
    "\n",
    "# 7. Confronto con i risultati del test descritto\n",
    "original_f1_score = 0.15  # F1-Score del test originale\n",
    "print(f\"F1-Score Originale: {original_f1_score}\")\n",
    "\n",
    "if new_f1_score > original_f1_score:\n",
    "    print(\"Il nuovo modello ha un F1-Score migliore rispetto al test originale.\")\n",
    "else:\n",
    "    print(\"Il nuovo modello non ha migliorato l'F1-Score rispetto al test originale.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882ac65a-7f6e-4738-9bde-4b7015e55504",
   "metadata": {},
   "source": [
    "I risultati ottenuti dal modello di classificazione sono interessanti e mostrano un miglioramento significativo rispetto al test originale. Ecco un'analisi dettagliata dei risultati:\n",
    "   \n",
    "*Precisione (Classe 1): 0.86*\n",
    "\n",
    "Questo valore indica che l'86% delle predizioni positive del modello sono corrette. È un valore molto alto, il che significa che il modello è molto preciso nel identificare i veri positivi.\n",
    "\n",
    "*Recall (Classe 1): 0.40*\n",
    "\n",
    "Il recall (o sensibilità) del 40% indica che il modello identifica correttamente il 40% dei casi positivi. Questo è inferiore alla sensibilità del test originale (90%), ma è importante notare che il test originale aveva un alto tasso di falsi positivi, che il modello sembra aver ridotto.\n",
    "   \n",
    "*F1-Score: 0.545*\n",
    "\n",
    "L'F1-Score è una media armonica tra precisione e recall. Il valore di 0.545 è significativamente migliore rispetto all'F1-Score originale di 0.15. Questo indica che il modello bilancia meglio precisione e recall rispetto al test originale.\n",
    "\n",
    "Matrice di Confusione:\n",
    "   \n",
    "Veri Negativi (True Negatives, TN): 2984\n",
    "\n",
    "Il modello ha correttamente identificato 2984 casi negativi.\n",
    "\n",
    "Falsi Positivi (False Positives, FP): 1\n",
    "\n",
    "Solo 1 caso è stato erroneamente identificato come positivo. Questo è un miglioramento significativo rispetto al tasso di falsi positivi del 5% del test originale.\n",
    "\n",
    "Falsi Negativi (False Negatives, FN): 9\n",
    "\n",
    "9 casi positivi sono stati erroneamente identificati come negativi. Questo è un po' alto, ma è un compromesso accettabile dato il miglioramento nella precisione.\n",
    "\n",
    "Veri Positivi (True Positives, TP): 6\n",
    "\n",
    "Il modello ha correttamente identificato 6 casi positivi.\n",
    "\n",
    "Considerazioni Finali:\n",
    "\n",
    "*Miglioramento della Precisione*: Il modello ha una precisione molto alta (86%), il che significa che quando predice un caso positivo, è molto probabile che sia corretto. Questo è un miglioramento significativo rispetto al test originale, che aveva una precisione dell'8%.\n",
    "\n",
    "*Compromesso sul Recall*: Il recall del 40% è inferiore alla sensibilità del test originale (90%), ma è un compromesso accettabile dato il miglioramento nella precisione e la riduzione dei falsi positivi.\n",
    "\n",
    "*Riduzione dei Falsi Positivi*: Il modello ha solo 1 falso positivo, il che è un miglioramento enorme rispetto ai 497 falsi positivi del test originale.\n",
    "\n",
    "Conclusioni:\n",
    "\n",
    "*Il nuovo modello ha un F1-Score significativamente migliore rispetto al test originale, il che indica che è più efficace nel bilanciare precisione e recall.*\n",
    "\n",
    "*Il modello ha una precisione molto alta e un basso tasso di falsi positivi, il che lo rende più affidabile per identificare i casi positivi.*\n",
    "\n",
    "*Il recall è inferiore rispetto al test originale, ma questo è un compromesso accettabile dato il miglioramento complessivo delle prestazioni del modello.*\n",
    "\n",
    "*In sintesi, il nuovo modello rappresenta un miglioramento significativo rispetto al test originale, specialmente in termini di precisione e riduzione dei falsi positivi. Tuttavia, potrebbe essere utile esplorare ulteriori tecniche per migliorare il recall senza compromettere la precisione.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855842e4-244d-4b95-a464-f3772118bddf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
